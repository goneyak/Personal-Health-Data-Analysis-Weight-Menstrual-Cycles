{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b6c4a17",
   "metadata": {},
   "source": [
    "\n",
    "# 05 — Summary Report\n",
    "\n",
    "This notebook consolidates key results from:\n",
    "1. **01_period_analysis.ipynb**\n",
    "2. **02_weight_analysis.ipynb**\n",
    "3. **03_weight_cycle_analysis.ipynb**\n",
    "4. **04_weight_cycle_kmeans.ipynb**\n",
    "\n",
    "It aggregates summary statistics, shows final figures (if present), and exports clean tables for your GitHub README.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Config =====\n",
    "FIG_DIR = \"figures\"\n",
    "SAVE_TABLES = True  # set False if you don't want CSVs saved\n",
    "EXPORT_DIR = \"exports\"\n",
    "\n",
    "import os\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Display full columns\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda96f37",
   "metadata": {},
   "source": [
    "## Load cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try pickle first (faster), then CSV\n",
    "def load_periods():\n",
    "    if Path(\"cleaned_periods.pkl\").exists():\n",
    "        return pd.read_pickle(\"cleaned_periods.pkl\")\n",
    "    elif Path(\"cleaned_periods.csv\").exists():\n",
    "        return pd.read_csv(\"cleaned_periods.csv\", parse_dates=[\"begin\",\"end\",\"ovulation_date\"])\n",
    "    else:\n",
    "        raise FileNotFoundError(\"cleaned_periods.csv/.pkl not found\")\n",
    "\n",
    "def load_weights():\n",
    "    if Path(\"cleaned_weights.pkl\").exists():\n",
    "        return pd.read_pickle(\"cleaned_weights.pkl\")\n",
    "    elif Path(\"cleaned_weights.csv\").exists():\n",
    "        return pd.read_csv(\"cleaned_weights.csv\", parse_dates=[\"Date\"])\n",
    "    else:\n",
    "        raise FileNotFoundError(\"cleaned_weights.csv/.pkl not found\")\n",
    "\n",
    "df_periods = load_periods().copy()\n",
    "df_weight = load_weights().copy()\n",
    "\n",
    "# Optional derived columns (if not already present)\n",
    "if \"cycle_length\" not in df_periods.columns and \"next_begin\" in df_periods.columns:\n",
    "    df_periods[\"cycle_length\"] = (df_periods[\"next_begin\"] - df_periods[\"begin\"]).dt.days\n",
    "\n",
    "if \"duration_days\" not in df_periods.columns and \"end\" in df_periods.columns:\n",
    "    df_periods[\"duration_days\"] = (df_periods[\"end\"] - df_periods[\"begin\"]).dt.days\n",
    "\n",
    "df_periods = df_periods.sort_values(\"begin\")\n",
    "df_weight = df_weight.sort_values(\"Date\")\n",
    "\n",
    "df_periods.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d4a50",
   "metadata": {},
   "source": [
    "## Key metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea444cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cycle-level metrics\n",
    "metrics = {}\n",
    "\n",
    "if \"cycle_length\" in df_periods.columns:\n",
    "    metrics[\"cycle_length_mean\"] = float(df_periods[\"cycle_length\"].mean())\n",
    "    metrics[\"cycle_length_sd\"] = float(df_periods[\"cycle_length\"].std())\n",
    "\n",
    "if \"duration_days\" in df_periods.columns:\n",
    "    metrics[\"period_duration_mean\"] = float(df_periods[\"duration_days\"].mean())\n",
    "    metrics[\"period_duration_sd\"] = float(df_periods[\"duration_days\"].std())\n",
    "\n",
    "# Count by year/season\n",
    "df_periods[\"year\"] = df_periods[\"begin\"].dt.year\n",
    "\n",
    "def get_season(dt):\n",
    "    m = dt.month\n",
    "    if m in [12,1,2]: return \"Winter\"\n",
    "    elif m in [3,4,5]: return \"Spring\"\n",
    "    elif m in [6,7,8]: return \"Summer\"\n",
    "    else: return \"Fall\"\n",
    "\n",
    "df_periods[\"season\"] = df_periods[\"begin\"].apply(get_season)\n",
    "\n",
    "by_year = df_periods[\"year\"].value_counts().sort_index()\n",
    "by_season = df_periods[\"season\"].value_counts().reindex([\"Winter\",\"Spring\",\"Summer\",\"Fall\"]).fillna(0).astype(int)\n",
    "\n",
    "print(\"=== Summary metrics ===\")\n",
    "for k,v in metrics.items():\n",
    "    print(f\"{k}: {v:.2f}\")\n",
    "print(\"\\nBy year:\")\n",
    "display(by_year.to_frame(\"count\"))\n",
    "print(\"\\nBy season:\")\n",
    "display(by_season.to_frame(\"count\"))\n",
    "\n",
    "if SAVE_TABLES:\n",
    "    pd.Series(metrics).to_json(os.path.join(EXPORT_DIR, \"summary_metrics.json\"), indent=2)\n",
    "    by_year.to_csv(os.path.join(EXPORT_DIR, \"counts_by_year.csv\"))\n",
    "    by_season.to_csv(os.path.join(EXPORT_DIR, \"counts_by_season.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907c735",
   "metadata": {},
   "source": [
    "## Cluster results (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ef42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you saved 'clustered_meta.csv' in your clustering notebook, load it.\n",
    "# Otherwise, this cell will skip quietly.\n",
    "clustered_meta = None\n",
    "cluster_path = Path(\"clustered_meta.csv\")\n",
    "if cluster_path.exists():\n",
    "    clustered_meta = pd.read_csv(cluster_path, parse_dates=[\"cycle_start\"])\n",
    "    print(\"Loaded clustered_meta.csv\")\n",
    "else:\n",
    "    print(\"clustered_meta.csv not found. Skipping cluster summaries.\")\n",
    "clustered_meta.head() if clustered_meta is not None else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if clustered_meta is not None:\n",
    "    df_joined = df_periods.merge(clustered_meta, left_on=\"begin\", right_on=\"cycle_start\", how=\"inner\")\n",
    "    cluster_counts = df_joined[\"cluster\"].value_counts().sort_index()\n",
    "\n",
    "    # cluster-level cycle/duration stats (if columns exist)\n",
    "    agg_cols = {}\n",
    "    if \"cycle_length\" in df_joined.columns:\n",
    "        agg_cols[\"mean_cycle_length\"] = (\"cycle_length\",\"mean\")\n",
    "        agg_cols[\"sd_cycle_length\"] = (\"cycle_length\",\"std\")\n",
    "    if \"duration_days\" in df_joined.columns:\n",
    "        agg_cols[\"mean_duration\"] = (\"duration_days\",\"mean\")\n",
    "        agg_cols[\"sd_duration\"] = (\"duration_days\",\"std\")\n",
    "\n",
    "    cluster_summary = (df_joined.groupby(\"cluster\").agg(**agg_cols) if agg_cols else pd.DataFrame())\n",
    "    display(cluster_counts.to_frame(\"count\"))\n",
    "    display(cluster_summary.round(2))\n",
    "\n",
    "    # season/year distributions\n",
    "    season_dist = pd.crosstab(df_joined[\"cluster\"], df_joined[\"season\"]).reindex(columns=[\"Winter\",\"Spring\",\"Summer\",\"Fall\"], fill_value=0)\n",
    "    year_dist = pd.crosstab(df_joined[\"cluster\"], df_joined[\"year\"]).sort_index(axis=1)\n",
    "    season_pct = (season_dist.div(season_dist.sum(axis=1), axis=0) * 100).round(1)\n",
    "    year_pct = (year_dist.div(year_dist.sum(axis=1), axis=0) * 100).round(1)\n",
    "\n",
    "    print(\"\\nSeason counts by cluster:\")\n",
    "    display(season_dist)\n",
    "    print(\"\\nSeason % by cluster:\")\n",
    "    display(season_pct)\n",
    "    print(\"\\nYear counts by cluster:\")\n",
    "    display(year_dist)\n",
    "    print(\"\\nYear % by cluster:\")\n",
    "    display(year_pct)\n",
    "\n",
    "    if SAVE_TABLES:\n",
    "        cluster_counts.to_csv(os.path.join(EXPORT_DIR, \"cluster_counts.csv\"))\n",
    "        if not cluster_summary.empty:\n",
    "            cluster_summary.round(2).to_csv(os.path.join(EXPORT_DIR, \"cluster_summary.csv\"))\n",
    "        season_dist.to_csv(os.path.join(EXPORT_DIR, \"cluster_season_counts.csv\"))\n",
    "        season_pct.to_csv(os.path.join(EXPORT_DIR, \"cluster_season_percent.csv\"))\n",
    "        year_dist.to_csv(os.path.join(EXPORT_DIR, \"cluster_year_counts.csv\"))\n",
    "        year_pct.to_csv(os.path.join(EXPORT_DIR, \"cluster_year_percent.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b842ce9c",
   "metadata": {},
   "source": [
    "## Figures (if present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2bf03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "def show_if_exists(path, caption=None, width=900):\n",
    "    if Path(path).exists():\n",
    "        display(Image(filename=path, width=width))\n",
    "        if caption:\n",
    "            print(caption)\n",
    "    else:\n",
    "        print(f\"[Missing] {path}\")\n",
    "\n",
    "# Weight × Cycle analysis figures\n",
    "show_if_exists(os.path.join(FIG_DIR, \"01_weight_timeline.png\"), \"Weight timeline with cycle shading\")\n",
    "show_if_exists(os.path.join(FIG_DIR, \"02_align_period_start.png\"), \"Aligned around Period Start\")\n",
    "show_if_exists(os.path.join(FIG_DIR, \"03_align_ovulation.png\"), \"Aligned around Ovulation\")\n",
    "show_if_exists(os.path.join(FIG_DIR, \"04_compare_period_vs_ovulation.png\"), \"Period vs Ovulation (mean ± 95% CI)\")\n",
    "\n",
    "# Optionally show cluster plots you saved manually (e.g., cluster_0.png, cluster_1.png, ...)\n",
    "for i in range(10):\n",
    "    p = os.path.join(FIG_DIR, f\"cluster_{i}.png\")\n",
    "    if Path(p).exists():\n",
    "        show_if_exists(p, f\"Cluster {i} pattern\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690554f6",
   "metadata": {},
   "source": [
    "## README helper: export quick markdown snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac491b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "md_lines = []\n",
    "\n",
    "# Metrics snippet\n",
    "md_lines.append(\"### Key Metrics\\n\")\n",
    "for k, v in (pd.read_json(os.path.join(EXPORT_DIR, \"summary_metrics.json\"), typ='series').to_dict()\n",
    "             if Path(os.path.join(EXPORT_DIR, \"summary_metrics.json\")).exists() else {}).items():\n",
    "    md_lines.append(f\"- **{k.replace('_',' ').title()}**: {v:.2f}\")\n",
    "md_lines.append(\"\\n\")\n",
    "\n",
    "# Cluster counts snippet\n",
    "cc_path = os.path.join(EXPORT_DIR, \"cluster_counts.csv\")\n",
    "if Path(cc_path).exists():\n",
    "    cc = pd.read_csv(cc_path, index_col=0)\n",
    "    md_lines.append(\"### Cluster Counts\\n\")\n",
    "    md_lines.append(cc.to_markdown())\n",
    "    md_lines.append(\"\\n\")\n",
    "\n",
    "# Season % by cluster snippet\n",
    "sp_path = os.path.join(EXPORT_DIR, \"cluster_season_percent.csv\")\n",
    "if Path(sp_path).exists():\n",
    "    sp = pd.read_csv(sp_path, index_col=0)\n",
    "    md_lines.append(\"### Seasonal Distribution by Cluster (%)\\n\")\n",
    "    md_lines.append(sp.to_markdown())\n",
    "    md_lines.append(\"\\n\")\n",
    "\n",
    "snippet = \"\\n\".join(md_lines) if md_lines else \"_Run the cells above first to generate snippets._\"\n",
    "print(snippet)\n",
    "\n",
    "# Save a copy to exports/readme_snippet.md\n",
    "with open(os.path.join(EXPORT_DIR, \"readme_snippet.md\"), \"w\") as f:\n",
    "    f.write(snippet)\n",
    "print(\"\\nSaved: exports/readme_snippet.md\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
